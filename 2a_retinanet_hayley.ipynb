{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "643e283a",
   "metadata": {},
   "source": [
    "Section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ded9494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycocotools in c:\\users\\owner\\anaconda3\\lib\\site-packages (2.0.11)\n",
      "Requirement already satisfied: numpy in c:\\users\\owner\\anaconda3\\lib\\site-packages (from pycocotools) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import sys, platform\n",
    "%pip install pycocotools\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import CocoDetection\n",
    "from pycocotools.coco import COCO\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "from torchvision.datasets import CocoDetection\n",
    "import torchvision.transforms.functional as F\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.retinanet import RetinaNet_ResNet50_FPN_Weights\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cf73d5",
   "metadata": {},
   "source": [
    "Section 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3883d6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "ROOT = Path(\"signs_coco\")\n",
    "IMG_DIR = ROOT / \"images\"\n",
    "ANN_FILE = ROOT / \"result.json\"\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cpu\") \n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dace4e9",
   "metadata": {},
   "source": [
    "Section 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0bc5ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Dropped attribute categories: ['Back', 'Circular', 'Damaged', 'Front', 'Good', 'Heavily Damaged', 'Octagonal', 'Pole-mounted', 'Side', 'Square', 'Triangular', 'Wall-mounted', 'Weathered']\n",
      "Number of sign-type classes: 25\n",
      "num_classes (incl background): 26\n",
      "Example idx: 0 boxes: 3 labels sample: [19, 22, 6]\n",
      "Example idx: 1 boxes: 2 labels sample: [22, 19]\n",
      "Example idx: 2 boxes: 2 labels sample: [19, 22]\n",
      "Found: 3\n"
     ]
    }
   ],
   "source": [
    "def transforms(img, target):\n",
    "    img = F.to_tensor(img)\n",
    "    return img, target\n",
    "\n",
    "ATTRIBUTE_NAMES = {\n",
    "    \"Front\", \"Side\", \"Back\",\n",
    "    \"Wall-mounted\", \"Pole-mounted\",\n",
    "    \"Good\", \"Weathered\", \"Heavily Damaged\", \"Damaged\",\n",
    "    \"Circular\", \"Square\", \"Triangular\", \"Octagonal\",\n",
    "}\n",
    "\n",
    "class CocoForSignTypeDetection(CocoDetection):\n",
    "    def __init__(self, img_folder, ann_file, transforms=None):\n",
    "        super().__init__(img_folder, ann_file)\n",
    "        self._transforms = transforms\n",
    "        self.img_folder = Path(img_folder)\n",
    "\n",
    "        cats = self.coco.loadCats(self.coco.getCatIds())\n",
    "        cats = sorted(cats, key=lambda c: c[\"id\"])\n",
    "\n",
    "        sign_cats = [c for c in cats if c[\"name\"] not in ATTRIBUTE_NAMES]\n",
    "\n",
    "        self.cat_id_to_contig = {c[\"id\"]: i + 1 for i, c in enumerate(sign_cats)}\n",
    "        self.contig_to_name = {i + 1: c[\"name\"] for i, c in enumerate(sign_cats)}\n",
    "        self.contig_to_cat_id = {v: k for k, v in self.cat_id_to_contig.items()}\n",
    "        self.num_classes = len(sign_cats) + 1\n",
    "\n",
    "        self._kept_names = [c[\"name\"] for c in sign_cats]\n",
    "        self._dropped_names = [c[\"name\"] for c in cats if c[\"name\"] in ATTRIBUTE_NAMES]\n",
    "\n",
    "    def _load_image(self, id: int):\n",
    "        # COCO json file_name may contain a Label Studio path; we only want the basename\n",
    "        file_name = self.coco.loadImgs(id)[0][\"file_name\"]\n",
    "        base = Path(file_name).name  # strips ../../label-studio/... and keeps IMG_xxx.jpg\n",
    "        img_path = self.img_folder / base\n",
    "        return Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        id = self.ids[idx]\n",
    "        img = self._load_image(id)\n",
    "        anns = self.coco.loadAnns(self.coco.getAnnIds(imgIds=id))\n",
    "\n",
    "        boxes, labels = [], []\n",
    "        for a in anns:\n",
    "            coco_cat_id = a[\"category_id\"]\n",
    "            if coco_cat_id not in self.cat_id_to_contig:\n",
    "                continue\n",
    "\n",
    "            x, y, w, h = a[\"bbox\"]\n",
    "            if w <= 1 or h <= 1:\n",
    "                continue\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(self.cat_id_to_contig[coco_cat_id])\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.int64),\n",
    "            \"image_id\": torch.tensor([id]),\n",
    "        }\n",
    "\n",
    "        if self._transforms:\n",
    "            img, target = self._transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "dataset = CocoForSignTypeDetection(str(IMG_DIR), str(ANN_FILE), transforms=transforms)\n",
    "\n",
    "print(\"Dropped attribute categories:\", sorted(dataset._dropped_names))\n",
    "print(\"Number of sign-type classes:\", dataset.num_classes - 1)\n",
    "print(\"num_classes (incl background):\", dataset.num_classes)\n",
    "\n",
    "found = 0\n",
    "for i in range(len(dataset)):\n",
    "    img, tgt = dataset[i]\n",
    "    if len(tgt[\"boxes\"]) > 0:\n",
    "        print(\"Example idx:\", i, \"boxes:\", len(tgt[\"boxes\"]), \"labels sample:\", tgt[\"labels\"][:5].tolist())\n",
    "        found += 1\n",
    "    if found == 3:\n",
    "        break\n",
    "\n",
    "print(\"Found:\", found)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ce88da",
   "metadata": {},
   "source": [
    "Section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "44c68cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 481 Val: 121\n"
     ]
    }
   ],
   "source": [
    "indices = list(range(len(dataset)))\n",
    "random.seed(42)\n",
    "random.shuffle(indices)\n",
    "\n",
    "split = int(0.8 * len(indices))\n",
    "train_ds = Subset(dataset, indices[:split])\n",
    "val_ds   = Subset(dataset, indices[split:])\n",
    "\n",
    "print(\"Train:\", len(train_ds), \"Val:\", len(val_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd96ff",
   "metadata": {},
   "source": [
    "Section 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af297e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "BATCH_SIZE = 2      \n",
    "NUM_WORKERS = 0     \n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "    num_workers=NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds, batch_size=1, shuffle=False,\n",
    "    num_workers=NUM_WORKERS, collate_fn=collate_fn\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0628c5ba",
   "metadata": {},
   "source": [
    "Section 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a8db0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ready. Classes incl background: 26\n",
      "Head num_classes: 26\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "weights = RetinaNet_ResNet50_FPN_Weights.DEFAULT\n",
    "\n",
    "model = torchvision.models.detection.retinanet_resnet50_fpn(weights=weights)\n",
    "\n",
    "from torchvision.models.detection.retinanet import RetinaNetClassificationHead\n",
    "num_anchors = model.head.classification_head.num_anchors\n",
    "\n",
    "first_block = model.head.classification_head.conv[0]\n",
    "conv0 = first_block[0]  \n",
    "in_channels = conv0.in_channels\n",
    "\n",
    "model.head.classification_head = RetinaNetClassificationHead(\n",
    "    in_channels=in_channels,\n",
    "    num_anchors=num_anchors,\n",
    "    num_classes=dataset.num_classes \n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "print(\"Model ready. Classes incl background:\", dataset.num_classes)\n",
    "print(\"Head num_classes:\", model.head.classification_head.num_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41cead63",
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_DIR = Path(\"checkpoints\")\n",
    "CKPT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def save_checkpoint(epoch, model, optimizer, avg_loss):\n",
    "    ckpt = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state\": model.state_dict(),\n",
    "        \"optim_state\": optimizer.state_dict(),\n",
    "        \"avg_loss\": avg_loss,\n",
    "        \"num_classes\": dataset.num_classes,\n",
    "        \"kept_names\": getattr(dataset, \"_kept_names\", None),\n",
    "    }\n",
    "    torch.save(ckpt, CKPT_DIR / f\"retinanet_epoch{epoch}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c65f1d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9512416d",
   "metadata": {},
   "source": [
    "Section 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e30e6ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classification': 1.231806993484497, 'bbox_regression': 0.6752537488937378}\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "images, targets = next(iter(train_loader))\n",
    "images = [img.to(device) for img in images]\n",
    "targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "loss_dict = model(images, targets)\n",
    "loss = sum(loss_dict.values())\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print({k: float(v.detach().cpu()) for k, v in loss_dict.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f546867d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/241 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     33\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 34\u001b[0m     avg_loss \u001b[38;5;241m=\u001b[39m train_one_epoch(epoch)\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | avg loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | time=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     36\u001b[0m     save_checkpoint(epoch, model, optimizer, avg_loss)\n",
      "Cell \u001b[1;32mIn[30], line 17\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(epoch)\u001b[0m\n\u001b[0;32m     14\u001b[0m images \u001b[38;5;241m=\u001b[39m [img\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images]\n\u001b[0;32m     15\u001b[0m targets \u001b[38;5;241m=\u001b[39m [{k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets]\n\u001b[1;32m---> 17\u001b[0m loss_dict \u001b[38;5;241m=\u001b[39m model(images, targets)\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(loss_dict\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;241m/\u001b[39m ACCUM_STEPS\n\u001b[0;32m     19\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torchvision\\models\\detection\\retinanet.py:629\u001b[0m, in \u001b[0;36mRetinaNet.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m    622\u001b[0m             torch\u001b[38;5;241m.\u001b[39m_assert(\n\u001b[0;32m    623\u001b[0m                 \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    624\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll bounding boxes should have positive height and width.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    625\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Found invalid box \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegen_bb\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for target at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_idx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    626\u001b[0m             )\n\u001b[0;32m    628\u001b[0m \u001b[38;5;66;03m# get the features from the backbone\u001b[39;00m\n\u001b[1;32m--> 629\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(images\u001b[38;5;241m.\u001b[39mtensors)\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    631\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torchvision\\models\\detection\\backbone_utils.py:57\u001b[0m, in \u001b[0;36mBackboneWithFPN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]:\n\u001b[1;32m---> 57\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbody(x)\n\u001b[0;32m     58\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfpn(x)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:69\u001b[0m, in \u001b[0;36mIntermediateLayerGetter.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     67\u001b[0m out \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m module(x)\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers:\n\u001b[0;32m     71\u001b[0m         out_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_layers[name]\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torchvision\\models\\resnet.py:158\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n\u001b[0;32m    160\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[0;32m    161\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32mc:\\Users\\owner\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    542\u001b[0m     )\n\u001b[1;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    544\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[0;32m    545\u001b[0m )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "EPOCHS = 20\n",
    "ACCUM_STEPS = 1  \n",
    "\n",
    "def train_one_epoch(epoch):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    pbar = tqdm(enumerate(train_loader), total=len(train_loader))\n",
    "    for step, (images, targets) in pbar:\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        loss_dict = model(images, targets)\n",
    "        loss = sum(loss_dict.values()) / ACCUM_STEPS\n",
    "        loss.backward()\n",
    "\n",
    "        if (step + 1) % ACCUM_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running += loss.item() * ACCUM_STEPS\n",
    "        pbar.set_description(f\"Epoch {epoch} | avg loss {running/(step+1):.4f}\")\n",
    "\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return running / max(1, len(train_loader))\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    t0 = time.time()\n",
    "    avg_loss = train_one_epoch(epoch)\n",
    "    print(f\"Epoch {epoch}/{EPOCHS} | avg loss={avg_loss:.4f} | time={time.time()-t0:.1f}s\")\n",
    "    save_checkpoint(epoch, model, optimizer, avg_loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c2392e",
   "metadata": {},
   "source": [
    "Section 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e86462",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "\n",
    "def _get_base_dataset(ds):\n",
    "    # handles Subset(dataset, indices)\n",
    "    return ds.dataset if hasattr(ds, \"dataset\") else ds\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_coco_bbox(model, data_loader, ds_for_meta, device, score_thresh=0.05):\n",
    "    model.eval()\n",
    "\n",
    "    base_ds = _get_base_dataset(ds_for_meta)\n",
    "    coco_gt = base_ds.coco\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for images, targets in data_loader:\n",
    "        images = [img.to(device) for img in images]\n",
    "        outputs = model(images)\n",
    "\n",
    "        for out, tgt in zip(outputs, targets):\n",
    "            image_id = int(tgt[\"image_id\"].item())\n",
    "\n",
    "            boxes = out[\"boxes\"].detach().cpu().numpy()\n",
    "            scores = out[\"scores\"].detach().cpu().numpy()\n",
    "            labels = out[\"labels\"].detach().cpu().numpy()\n",
    "\n",
    "            keep = scores >= score_thresh\n",
    "            boxes, scores, labels = boxes[keep], scores[keep], labels[keep]\n",
    "\n",
    "            for b, s, l in zip(boxes, scores, labels):\n",
    "                x1, y1, x2, y2 = b.tolist()\n",
    "                w, h = x2 - x1, y2 - y1\n",
    "\n",
    "                coco_cat_id = base_ds.contig_to_cat_id.get(int(l), None)\n",
    "                if coco_cat_id is None:\n",
    "                    continue\n",
    "\n",
    "                results.append({\n",
    "                    \"image_id\": image_id,\n",
    "                    \"category_id\": int(coco_cat_id),\n",
    "                    \"bbox\": [x1, y1, w, h],     # COCO wants xywh\n",
    "                    \"score\": float(s),\n",
    "                })\n",
    "\n",
    "    if len(results) == 0:\n",
    "        print(\"No predictions above threshold. Try lowering score_thresh (e.g. 0.01).\")\n",
    "        return None\n",
    "\n",
    "    coco_dt = coco_gt.loadRes(results)\n",
    "    coco_eval = COCOeval(coco_gt, coco_dt, iouType=\"bbox\")\n",
    "    coco_eval.evaluate()\n",
    "    coco_eval.accumulate()\n",
    "    coco_eval.summarize()\n",
    "\n",
    "    stats = coco_eval.stats\n",
    "    metrics = {\n",
    "        \"AP@[.5:.95]\": float(stats[0]),\n",
    "        \"AP@0.5\": float(stats[1]),\n",
    "        \"AP@0.75\": float(stats[2]),\n",
    "        \"AP_small\": float(stats[3]),\n",
    "        \"AP_medium\": float(stats[4]),\n",
    "        \"AP_large\": float(stats[5]),\n",
    "        \"AR@1\": float(stats[6]),\n",
    "        \"AR@10\": float(stats[7]),\n",
    "        \"AR@100\": float(stats[8]),\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "metrics = evaluate_coco_bbox(model, val_loader, val_ds, device, score_thresh=0.05)\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970d64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def show_val_predictions(model, val_ds, base_dataset, n=8, score_thresh=0.4, seed=42):\n",
    "    model.eval()\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    idxs = torch.randint(low=0, high=len(val_ds), size=(n,), generator=g).tolist()\n",
    "\n",
    "    for j, subset_idx in enumerate(idxs):\n",
    "        img, tgt = val_ds[subset_idx]   \n",
    "        out = model([img.to(device)])[0]\n",
    "\n",
    "        keep = out[\"scores\"] >= score_thresh\n",
    "        p_boxes = out[\"boxes\"][keep].cpu()\n",
    "        p_scores = out[\"scores\"][keep].cpu()\n",
    "        p_labels = out[\"labels\"][keep].cpu()\n",
    "\n",
    "        pred_text = []\n",
    "        for l, s in zip(p_labels.tolist(), p_scores.tolist()):\n",
    "            name = base_dataset.contig_to_name.get(int(l), f\"class{l}\")\n",
    "            pred_text.append(f\"{name}:{s:.2f}\")\n",
    "\n",
    "        img_u8 = (img * 255).to(torch.uint8)\n",
    "        pred_img = torchvision.utils.draw_bounding_boxes(\n",
    "            img_u8, p_boxes, labels=pred_text, width=2\n",
    "        )\n",
    "\n",
    "        gt_boxes = tgt[\"boxes\"].cpu()\n",
    "        gt_labels = tgt[\"labels\"].cpu()\n",
    "        gt_text = [base_dataset.contig_to_name.get(int(l), f\"class{l}\") for l in gt_labels.tolist()]\n",
    "        gt_img = torchvision.utils.draw_bounding_boxes(\n",
    "            img_u8, gt_boxes, labels=gt_text, width=2\n",
    "        )\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(pred_img.permute(1,2,0))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"[PRED] val_subset_idx={subset_idx} | preds={len(p_boxes)} | thresh={score_thresh}\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.imshow(gt_img.permute(1,2,0))\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"[GT] val_subset_idx={subset_idx} | gt_boxes={len(gt_boxes)}\")\n",
    "        plt.show()\n",
    "\n",
    "show_val_predictions(model, val_ds, dataset, n=6, score_thresh=0.4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
